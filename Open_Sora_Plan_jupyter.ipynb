{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xCarnival/Cipher/blob/main/Open_Sora_Plan_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "99c21945-9411-4d3c-e23e-22f89c6a0206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'Open-Sora-Plan-v1.0.0-hf' already exists and is not an empty directory.\n",
            "/content/Open-Sora-Plan-v1.0.0-hf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'is_mlu_available' from 'accelerate.utils' (/usr/local/lib/python3.10/dist-packages/accelerate/utils/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0maccelerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maccelerate_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     from accelerate.utils import (\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mDistributedDataParallelKwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_mlu_available' from 'accelerate.utils' (/usr/local/lib/python3.10/dist-packages/accelerate/utils/__init__.py)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-20ef50efed0f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5EncoderModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopensora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mae_stride_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetae_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopensora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_latte\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatteT2V\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopensora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_videogen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoGenPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Open-Sora-Plan-v1.0.0-hf/opensora/models/ae/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimagebase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimagebase_ae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimagebase_ae_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimagebase_ae_channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideobase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvideobase_ae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideobase_ae_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideobase_ae_channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m from .videobase import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mVQVAEConfiguration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mVQVAEModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Open-Sora-Plan-v1.0.0-hf/opensora/models/ae/videobase/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .vqvae import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mVQVAEConfiguration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mVQVAEModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mVQVAETrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mVQVAEModelWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Open-Sora-Plan-v1.0.0-hf/opensora/models/ae/videobase/vqvae/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_vqvae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVQVAEConfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_vqvae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVQVAEModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer_vqvae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVQVAETrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m videovqvae = [\n",
            "\u001b[0;32m/content/Open-Sora-Plan-v1.0.0-hf/opensora/models/ae/videobase/vqvae/trainer_vqvae.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_videobase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoBaseTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Open-Sora-Plan-v1.0.0-hf/opensora/models/ae/videobase/trainer_videobase.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1594\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1606\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'is_mlu_available' from 'accelerate.utils' (/usr/local/lib/python3.10/dist-packages/accelerate/utils/__init__.py)"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/Open-Sora-Plan-v1.0.0-hf\n",
        "%cd /content/Open-Sora-Plan-v1.0.0-hf\n",
        "!pip install -q diffusers==0.24.0 gradio==3.50.2 einops==0.7.0 omegaconf==2.1.1 pytorch-lightning==1.4.2 torchmetrics==0.6.0 torchtext==0.6 accelerate -U # Upgraded accelerate to the latest version\n",
        "\n",
        "import os\n",
        "import random\n",
        "import imageio\n",
        "import torch\n",
        "from diffusers import PNDMScheduler\n",
        "from datetime import datetime\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from gradio.components import Textbox, Video, Image\n",
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "\n",
        "from opensora.models.ae import ae_stride_config, getae, getae_wrapper\n",
        "from opensora.models.diffusion.latte.modeling_latte import LatteT2V\n",
        "from opensora.sample.pipeline_videogen import VideoGenPipeline\n",
        "from opensora.serve.gradio_utils import block_css, title_markdown, randomize_seed_fn, set_env, examples, DESCRIPTION\n",
        "\n",
        "\n",
        "def generate_img(prompt, sample_steps, scale, seed=0, randomize_seed=False, force_images=False):\n",
        "    seed = int(randomize_seed_fn(seed, randomize_seed))\n",
        "    set_env(seed)\n",
        "    video_length = transformer_model.config.video_length if not force_images else 1\n",
        "    height, width = int(args.version.split('x')[1]), int(args.version.split('x')[2])\n",
        "    num_frames = 1 if video_length == 1 else int(args.version.split('x')[0])\n",
        "    with torch.no_grad():\n",
        "        videos = videogen_pipeline(prompt,\n",
        "                                   video_length=video_length,\n",
        "                                   height=height,\n",
        "                                   width=width,\n",
        "                                   num_inference_steps=sample_steps,\n",
        "                                   guidance_scale=scale,\n",
        "                                   enable_temporal_attentions=not force_images,\n",
        "                                   num_images_per_prompt=1,\n",
        "                                   mask_feature=True,\n",
        "                                   ).video\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    videos = videos[0]\n",
        "    tmp_save_path = 'tmp.mp4'\n",
        "    imageio.mimwrite(tmp_save_path, videos, fps=24, quality=9)  # highest quality is 10, lowest is 0\n",
        "    display_model_info = f\"Video size: {num_frames}×{height}×{width}, \\nSampling Step: {sample_steps}, \\nGuidance Scale: {scale}\"\n",
        "    return tmp_save_path, prompt, display_model_info, seed\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = type('args', (), {\n",
        "        'ae': 'CausalVAEModel_4x8x8',\n",
        "        'force_images': False,\n",
        "        'model_path': 'LanguageBind/Open-Sora-Plan-v1.0.0',\n",
        "        'text_encoder_name': 'DeepFloyd/t5-v1_1-xxl',\n",
        "        'version': '65x512x512'\n",
        "    })\n",
        "    device = torch.device('cuda:0')\n",
        "\n",
        "    # Load model:\n",
        "    transformer_model = LatteT2V.from_pretrained(args.model_path, subfolder=args.version, torch_dtype=torch.float16, cache_dir='cache_dir').to(device)\n",
        "\n",
        "    vae = getae_wrapper(args.ae)(args.model_path, subfolder=\"vae\", cache_dir='cache_dir').to(device, dtype=torch.float16)\n",
        "    vae.vae.enable_tiling()\n",
        "    image_size = int(args.version.split('x')[1])\n",
        "    latent_size = (image_size // ae_stride_config[args.ae][1], image_size // ae_stride_config[args.ae][2])\n",
        "    vae.latent_size = latent_size\n",
        "    transformer_model.force_images = args.force_images\n",
        "    tokenizer = T5Tokenizer.from_pretrained(args.text_encoder_name, cache_dir=\"cache_dir\")\n",
        "    text_encoder = T5EncoderModel.from_pretrained(args.text_encoder_name, cache_dir=\"cache_dir\",\n",
        "                                                  torch_dtype=torch.float16).to(device)\n",
        "\n",
        "    # set eval mode\n",
        "    transformer_model.eval()\n",
        "    vae.eval()\n",
        "    text_encoder.eval()\n",
        "    scheduler = PNDMScheduler()\n",
        "    videogen_pipeline = VideoGenPipeline(vae=vae,\n",
        "                                         text_encoder=text_encoder,\n",
        "                                         tokenizer=tokenizer,\n",
        "                                         scheduler=scheduler,\n",
        "                                         transformer=transformer_model).to(device=device)\n",
        "\n",
        "\n",
        "    demo = gr.Interface(\n",
        "        fn=generate_img,\n",
        "        inputs=[Textbox(label=\"\",\n",
        "                        placeholder=\"A red panda surfing the stars. \\n\"),\n",
        "                gr.Slider(\n",
        "                    label='Sample Steps',\n",
        "                    minimum=1,\n",
        "                    maximum=500,\n",
        "                    value=50,\n",
        "                    step=10\n",
        "                ),\n",
        "                gr.Slider(\n",
        "                    label='Guidance Scale',\n",
        "                    minimum=0.1,\n",
        "                    maximum=30.0,\n",
        "                    value=10.0,\n",
        "                    step=0.1\n",
        "                ),\n",
        "                gr.Slider(\n",
        "                    label=\"Seed\",\n",
        "                    minimum=0,\n",
        "                    maximum=203279,\n",
        "                    step=1,\n",
        "                    value=0,\n",
        "                ),\n",
        "                gr.Checkbox(label=\"Randomize seed\", value=True),\n",
        "                gr.Checkbox(label=\"Generate image (1 frame video)\", value=False),\n",
        "                ],\n",
        "        outputs=[Video(label=\"Vid\", width=512, height=512),\n",
        "                 Textbox(label=\"input prompt\"),\n",
        "                 Textbox(label=\"model info\"),\n",
        "                 gr.Slider(label='seed')],\n",
        "        title=title_markdown, description=DESCRIPTION, theme=gr.themes.Default(), css=block_css,\n",
        "        examples=examples,\n",
        "    )\n",
        "    demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}